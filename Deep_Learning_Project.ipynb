{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning Project",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/serenal96/Deep-Learning-Project-AQM/blob/master/Deep_Learning_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "anaZBrcGIxIn",
        "colab_type": "code",
        "outputId": "33202387-0913-4111-b741-65ba275b462d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/serenal96/Deep-Learning-Project-AQM.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Deep-Learning-Project-AQM'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 89 (delta 3), reused 2 (delta 0), pack-reused 79\u001b[K\n",
            "Unpacking objects: 100% (89/89), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "swoInSBsxR3C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import h5py\n",
        "import numpy as np\n",
        "import torch\n",
        "from six import iteritems\n",
        "from six.moves import range\n",
        "from sklearn.preprocessing import normalize\n",
        "from torch.utils.data import Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KPgIwg9rkreC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "DataLoader.py"
      ]
    },
    {
      "metadata": {
        "id": "OWeIhukaxYEu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class VisDialDataset(Dataset):\n",
        "    def __init__(self, params, subsets, quiet=False):\n",
        "        '''\n",
        "            Initialize the dataset with splits given by 'subsets', where\n",
        "            subsets is taken from ['train', 'val', 'test']\n",
        "\n",
        "            Notation:\n",
        "                'dtype' is a split taking values from ['train', 'val', 'test']\n",
        "                'stype' is a sqeuence type from ['ques', 'ans']\n",
        "        '''\n",
        "\n",
        "        # By default, load Q-Bot, A-Bot and dialog options for A-Bot\n",
        "        self.useQuestion = True\n",
        "        self.useAnswer = True\n",
        "        self.useOptions = True\n",
        "        self.useHistory = True\n",
        "        self.useIm = True\n",
        "\n",
        "        # Absorb parameters\n",
        "        for key, value in iteritems(params):\n",
        "            setattr(self, key, value)\n",
        "        self.subsets = tuple(subsets)\n",
        "        self.numRounds = params['numRounds']\n",
        "\n",
        "        if not quiet:\n",
        "            print('\\nDataloader loading json file: ' + self.inputJson)\n",
        "        with open(self.inputJson, 'r') as fileId:\n",
        "            info = json.load(fileId)\n",
        "            # Absorb values\n",
        "            for key, value in iteritems(info):\n",
        "                setattr(self, key, value)\n",
        "\n",
        "        wordCount = len(self.word2ind)\n",
        "        # Add <START> and <END> to vocabulary\n",
        "        self.word2ind['<START>'] = wordCount + 1\n",
        "        self.word2ind['<END>'] = wordCount + 2\n",
        "        self.startToken = self.word2ind['<START>']\n",
        "        self.endToken = self.word2ind['<END>']\n",
        "        # Padding token is at index 0\n",
        "        self.vocabSize = wordCount + 3\n",
        "        if not quiet:\n",
        "            print('Vocab size with <START>, <END>: %d' % self.vocabSize)\n",
        "\n",
        "        # Construct the reverse map\n",
        "        self.ind2word = {\n",
        "            int(ind): word\n",
        "            for word, ind in iteritems(self.word2ind)\n",
        "        }\n",
        "\n",
        "        # Read questions, answers and options\n",
        "        if not quiet:\n",
        "            print('Dataloader loading h5 file: ' + self.inputQues)\n",
        "        quesFile = h5py.File(self.inputQues, 'r')\n",
        "\n",
        "        if self.useIm:\n",
        "            # Read images\n",
        "            if not quiet:\n",
        "                print('Dataloader loading h5 file: ' + self.inputImg)\n",
        "            imgFile = h5py.File(self.inputImg, 'r')\n",
        "\n",
        "        # Number of data points in each split (train/val/test)\n",
        "        self.numDataPoints = {}\n",
        "        self.data = {}\n",
        "\n",
        "        # map from load to save labels\n",
        "        ioMap = {\n",
        "            'ques_%s': '%s_ques',\n",
        "            'ques_length_%s': '%s_ques_len',\n",
        "            'ans_%s': '%s_ans',\n",
        "            'ans_length_%s': '%s_ans_len',\n",
        "            'ans_index_%s': '%s_ans_ind',\n",
        "            'img_pos_%s': '%s_img_pos',\n",
        "            'opt_%s': '%s_opt',\n",
        "            'opt_length_%s': '%s_opt_len',\n",
        "            'opt_list_%s': '%s_opt_list'\n",
        "        }\n",
        "\n",
        "        # Processing every split in subsets\n",
        "        for dtype in subsets:  # dtype is in [train, val, test]\n",
        "            if not quiet:\n",
        "                print(\"\\nProcessing split [%s]...\" % dtype)\n",
        "            if ('ques_%s' % dtype) not in quesFile:\n",
        "                self.useQuestion = False\n",
        "            if ('ans_%s' % dtype) not in quesFile:\n",
        "                self.useAnswer = False\n",
        "            if ('opt_%s' % dtype) not in quesFile:\n",
        "                self.useOptions = False\n",
        "            # read the question, answer, option related information\n",
        "            for loadLabel, saveLabel in iteritems(ioMap):\n",
        "                if loadLabel % dtype not in quesFile:\n",
        "                    continue\n",
        "                dataMat = np.array(quesFile[loadLabel % dtype], dtype='int64')\n",
        "                self.data[saveLabel % dtype] = torch.from_numpy(dataMat)\n",
        "\n",
        "            # Read image features, if needed\n",
        "            if self.useIm:\n",
        "                if not quiet:\n",
        "                        print('Reading image features...')\n",
        "                imgFeats = np.array(imgFile['images_' + dtype])\n",
        "\n",
        "                if not self.imgNorm:\n",
        "                    continue\n",
        "                # normalize, if needed\n",
        "                if not quiet:\n",
        "                        print('Normalizing image features..')\n",
        "                imgFeats = normalize(imgFeats, axis=1, norm='l2')\n",
        "\n",
        "                # save img features\n",
        "                self.data['%s_img_fv' % dtype] = torch.FloatTensor(imgFeats)\n",
        "                # Visdial\n",
        "                if hasattr(self, 'unique_img_train') and params['cocoDir']:\n",
        "                    coco_dir = params['cocoDir']\n",
        "                    with open(params['cocoInfo'], 'r') as f:\n",
        "                        coco_info = json.load(f)\n",
        "                    id_to_fname = {\n",
        "                        im['id']: im['file_path']\n",
        "                        for im in coco_info['images']\n",
        "                    }\n",
        "                    cocoids = getattr(self, 'unique_img_%s'%dtype)\n",
        "                    if '.jpg' not in cocoids[0]:\n",
        "                        img_fnames = [\n",
        "                            os.path.join(coco_dir, id_to_fname[int(cocoid)])\n",
        "                            for cocoid in cocoids\n",
        "                        ]\n",
        "                    else:\n",
        "                        img_fnames = cocoids\n",
        "                    self.data['%s_img_fnames' % dtype] = img_fnames\n",
        "\n",
        "            # read the history, if needed\n",
        "            if self.useHistory:\n",
        "                captionMap = {\n",
        "                    'cap_%s': '%s_cap',\n",
        "                    'cap_length_%s': '%s_cap_len'\n",
        "                }\n",
        "                for loadLabel, saveLabel in iteritems(captionMap):\n",
        "                    mat = np.array(quesFile[loadLabel % dtype], dtype='int32')\n",
        "                    self.data[saveLabel % dtype] = torch.from_numpy(mat)\n",
        "\n",
        "            # Number of data points\n",
        "            self.numDataPoints[dtype] = self.data[dtype + '_cap'].size(0)\n",
        "\n",
        "        # Prepare dataset for training\n",
        "        for dtype in subsets:\n",
        "            if not quiet:\n",
        "                print(\"\\nSequence processing for [%s]...\" % dtype)\n",
        "            self.prepareDataset(dtype)\n",
        "        if not quiet:\n",
        "            print(\"\\nSequence processing for [%s]...\" % dtype)\n",
        "\n",
        "        # Default pytorch loader dtype is set to train\n",
        "        if 'train' in subsets:\n",
        "            self._split = 'train'\n",
        "        else:\n",
        "            self._split = subsets[0]\n",
        "\n",
        "    @property\n",
        "    def split(self):\n",
        "        return self._split\n",
        "\n",
        "    @split.setter\n",
        "    def split(self, split):\n",
        "        assert split in self.subsets  # ['train', 'val', 'test']\n",
        "        self._split = split\n",
        "\n",
        "    #----------------------------------------------------------------------------\n",
        "    # Dataset preprocessing\n",
        "    #----------------------------------------------------------------------------\n",
        "\n",
        "    def prepareDataset(self, dtype):\n",
        "        if self.useHistory:\n",
        "            self.processCaption(dtype)\n",
        "\n",
        "        # prefix/postfix with <START> and <END>\n",
        "        if self.useOptions:\n",
        "            self.processOptions(dtype)\n",
        "            # options are 1-indexed, changed to 0-indexed\n",
        "            self.data[dtype + '_opt'] -= 1\n",
        "\n",
        "        # process answers and questions\n",
        "        if self.useAnswer:\n",
        "            self.processSequence(dtype, stype='ans')\n",
        "            # 1 indexed to 0 indexed\n",
        "            self.data[dtype + '_ans_ind'] -= 1\n",
        "        if self.useQuestion:\n",
        "            self.processSequence(dtype, stype='ques')\n",
        "\n",
        "    def processSequence(self, dtype, stype='ans'):\n",
        "        '''\n",
        "        Add <START> and <END> token to answers or questions.\n",
        "        Arguments:\n",
        "            'dtype'    : Split to use among ['train', 'val', 'test']\n",
        "            'sentType' : Sequence type, either 'ques' or 'ans'\n",
        "        '''\n",
        "        assert stype in ['ques', 'ans']\n",
        "        prefix = dtype + \"_\" + stype\n",
        "\n",
        "        seq = self.data[prefix]\n",
        "        seqLen = self.data[prefix + '_len']\n",
        "\n",
        "        numConvs, numRounds, maxAnsLen = seq.size()\n",
        "        newSize = torch.Size([numConvs, numRounds, maxAnsLen + 2])\n",
        "        sequence = torch.LongTensor(newSize).fill_(0)\n",
        "\n",
        "        # decodeIn begins with <START>\n",
        "        sequence[:, :, 0] = self.word2ind['<START>']\n",
        "        endTokenId = self.word2ind['<END>']\n",
        "\n",
        "        for thId in range(numConvs):\n",
        "            for rId in range(numRounds):\n",
        "                length = seqLen[thId, rId]\n",
        "                if length == 0:\n",
        "                    print('Warning: Skipping empty %s sequence at (%d, %d)'\\\n",
        "                          %(stype, thId, rId))\n",
        "                    continue\n",
        "\n",
        "                sequence[thId, rId, 1:length + 1] = seq[thId, rId, :length]\n",
        "                sequence[thId, rId, length + 1] = endTokenId\n",
        "\n",
        "        # Sequence length is number of tokens + 1\n",
        "        self.data[prefix + \"_len\"] = seqLen + 1\n",
        "        self.data[prefix] = sequence\n",
        "\n",
        "    def processCaption(self, dtype):\n",
        "        '''\n",
        "        Add <START> and <END> token to caption.\n",
        "        Arguments:\n",
        "            'dtype'    : Split to use among ['train', 'val', 'test']\n",
        "        '''\n",
        "        prefix = dtype + '_cap'\n",
        "\n",
        "        seq = self.data[prefix]\n",
        "        seqLen = self.data[prefix + '_len']\n",
        "\n",
        "        numConvs, maxCapLen = seq.size()\n",
        "        newSize = torch.Size([numConvs, maxCapLen + 2])\n",
        "        sequence = torch.LongTensor(newSize).fill_(0)\n",
        "\n",
        "        # decodeIn begins with <START>\n",
        "        sequence[:, 0] = self.word2ind['<START>']\n",
        "        endTokenId = self.word2ind['<END>']\n",
        "\n",
        "        for thId in range(numConvs):\n",
        "            length = seqLen[thId]\n",
        "            if length == 0:\n",
        "                print('Warning: Skipping empty %s sequence at (%d)' % (stype,\n",
        "                                                                       thId))\n",
        "                continue\n",
        "\n",
        "            sequence[thId, 1:length + 1] = seq[thId, :length]\n",
        "            sequence[thId, length + 1] = endTokenId\n",
        "\n",
        "        # Sequence length is number of tokens + 1\n",
        "        self.data[prefix + \"_len\"] = seqLen + 1\n",
        "        self.data[prefix] = sequence\n",
        "\n",
        "    def processOptions(self, dtype):\n",
        "        ans = self.data[dtype + '_opt_list']\n",
        "        ansLen = self.data[dtype + '_opt_len']\n",
        "\n",
        "        ansListLen, maxAnsLen = ans.size()\n",
        "\n",
        "        newSize = torch.Size([ansListLen, maxAnsLen + 2])\n",
        "        options = torch.LongTensor(newSize).fill_(0)\n",
        "\n",
        "        # decodeIn begins with <START>\n",
        "        options[:, 0] = self.word2ind['<START>']\n",
        "        endTokenId = self.word2ind['<END>']\n",
        "\n",
        "        for ansId in range(ansListLen):\n",
        "            length = ansLen[ansId]\n",
        "            if length == 0:\n",
        "                print('Warning: Skipping empty option answer list at (%d)'\\\n",
        "                        %ansId)\n",
        "                continue\n",
        "\n",
        "            options[ansId, 1:length + 1] = ans[ansId, :length]\n",
        "            options[ansId, length + 1] = endTokenId\n",
        "\n",
        "        self.data[dtype + '_opt_len'] = ansLen + 1\n",
        "        self.data[dtype + '_opt_seq'] = options\n",
        "\n",
        "    #----------------------------------------------------------------------------\n",
        "    # Dataset helper functions for PyTorch's datalaoder\n",
        "    #----------------------------------------------------------------------------\n",
        "\n",
        "    def __len__(self):\n",
        "        # Assert that loader_dtype is in subsets ['train', 'val', 'test']\n",
        "        return self.numDataPoints[self._split]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.getIndexItem(self._split, idx)\n",
        "        return item\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        out = {}\n",
        "\n",
        "        mergedBatch = {key: [d[key] for d in batch] for key in batch[0]}\n",
        "        for key in mergedBatch:\n",
        "            if key == 'img_fname' or key == 'index':\n",
        "                out[key] = mergedBatch[key]\n",
        "            elif key == 'cap_len':\n",
        "                # 'cap_lens' are single integers, need special treatment\n",
        "                out[key] = torch.LongTensor(mergedBatch[key])\n",
        "            else:\n",
        "                out[key] = torch.stack(mergedBatch[key], 0)\n",
        "\n",
        "        # Dynamic shaping of padded batch\n",
        "        if 'ques' in out.keys():\n",
        "            quesLen = out['ques_len'] + 1\n",
        "            out['ques'] = out['ques'][:, :, :torch.max(quesLen)].contiguous()\n",
        "\n",
        "        if 'ans' in out.keys():\n",
        "            ansLen = out['ans_len'] + 1\n",
        "            out['ans'] = out['ans'][:, :, :torch.max(ansLen)].contiguous()\n",
        "\n",
        "        if 'cap' in out.keys():\n",
        "            capLen = out['cap_len'] + 1\n",
        "            out['cap'] = out['cap'][:, :torch.max(capLen)].contiguous()\n",
        "\n",
        "        if 'opt' in out.keys():\n",
        "            optLen = out['opt_len'] + 1\n",
        "            out['opt'] = out['opt'][:, :, :, :torch.max(optLen) + 2].contiguous()\n",
        "\n",
        "        return out\n",
        "\n",
        "    #----------------------------------------------------------------------------\n",
        "    # Dataset indexing\n",
        "    #----------------------------------------------------------------------------\n",
        "\n",
        "    def getIndexItem(self, dtype, idx):\n",
        "        item = {'index': idx}\n",
        "\n",
        "        # get question\n",
        "        if self.useQuestion:\n",
        "            ques = self.data[dtype + '_ques'][idx]\n",
        "            quesLen = self.data[dtype + '_ques_len'][idx]\n",
        "            item['ques'] = ques\n",
        "            item['ques_len'] = quesLen\n",
        "\n",
        "        # get answer\n",
        "        if self.useAnswer:\n",
        "            ans = self.data[dtype + '_ans'][idx]\n",
        "            ansLen = self.data[dtype + '_ans_len'][idx]\n",
        "            item['ans_len'] = ansLen\n",
        "            item['ans'] = ans\n",
        "\n",
        "        # get caption\n",
        "        if self.useHistory:\n",
        "            cap = self.data[dtype + '_cap'][idx]\n",
        "            capLen = self.data[dtype + '_cap_len'][idx]\n",
        "            item['cap'] = cap\n",
        "            item['cap_len'] = capLen\n",
        "\n",
        "        if self.useOptions:\n",
        "            optInds = self.data[dtype + '_opt'][idx]\n",
        "            ansId = self.data[dtype + '_ans_ind'][idx]\n",
        "\n",
        "            optSize = list(optInds.size())\n",
        "            newSize = torch.Size(optSize + [-1])\n",
        "\n",
        "            indVector = optInds.view(-1)\n",
        "            optLens = self.data[dtype + '_opt_len'].index_select(0, indVector)\n",
        "            optLens = optLens.view(optSize)\n",
        "\n",
        "            opts = self.data[dtype + '_opt_seq'].index_select(0, indVector)\n",
        "\n",
        "            item['opt'] = opts.view(newSize)\n",
        "            item['opt_len'] = optLens\n",
        "            item['ans_id'] = ansId\n",
        "\n",
        "        # if image needed\n",
        "        if self.useIm:\n",
        "            item['img_feat'] = self.data[dtype + '_img_fv'][idx]\n",
        "            # item['img_fname'] = self.data[dtype + '_img_fnames'][idx]\n",
        "            if dtype + '_img_labels' in self.data:\n",
        "                item['img_label'] = self.data[dtype + '_img_labels'][idx]\n",
        "\n",
        "        return item\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1xIZWbJelHTg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Setup.py"
      ]
    },
    {
      "metadata": {
        "id": "Xf-uC-uIsI1x",
        "colab_type": "code",
        "outputId": "70344d01-5ee9-41d1-9a6e-fa2943b36bd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls /content"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Deep-Learning-Project-AQM  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BvBOH_gztEY1",
        "colab_type": "code",
        "outputId": "0fc5382d-1e54-4896-e76e-fce0398b8191",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2655
        }
      },
      "cell_type": "code",
      "source": [
        "!python /content/Deep-Learning-Project-AQM/setup.py install\n",
        "# print(\"Done.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating AQM.egg-info\n",
            "writing AQM.egg-info/PKG-INFO\n",
            "writing dependency_links to AQM.egg-info/dependency_links.txt\n",
            "writing requirements to AQM.egg-info/requires.txt\n",
            "writing top-level names to AQM.egg-info/top_level.txt\n",
            "writing manifest file 'AQM.egg-info/SOURCES.txt'\n",
            "reading manifest file 'AQM.egg-info/SOURCES.txt'\n",
            "writing manifest file 'AQM.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "warning: install_lib: 'build/lib' does not exist -- no Python modules to install\n",
            "\n",
            "creating build\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying AQM.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying AQM.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying AQM.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying AQM.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying AQM.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/AQM-1.0-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing AQM-1.0-py3.6.egg\n",
            "Copying AQM-1.0-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding AQM 1.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/AQM-1.0-py3.6.egg\n",
            "Processing dependencies for AQM==1.0\n",
            "Searching for markdown2\n",
            "Reading https://pypi.org/simple/markdown2/\n",
            "Downloading https://files.pythonhosted.org/packages/e4/0c/b5375c1c70adbafd0ded0459fa175468559ee5360219070d2f7fb60b2287/markdown2-2.3.7-py2.py3-none-any.whl#sha256=7edaa8ecc2843b4404e1cb754a52d1d135ecf181b475d2f32bbc36a562ef407d\n",
            "Best match: markdown2 2.3.7\n",
            "Processing markdown2-2.3.7-py2.py3-none-any.whl\n",
            "Installing markdown2-2.3.7-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding markdown2 2.3.7 to easy-install.pth file\n",
            "Installing markdown2 script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/markdown2-2.3.7-py3.6.egg\n",
            "Searching for visdom\n",
            "Reading https://pypi.org/simple/visdom/\n",
            "Downloading https://files.pythonhosted.org/packages/97/c4/5f5356fd57ae3c269e0e31601ea6487e0622fedc6756a591e4a5fd66cc7a/visdom-0.1.8.8.tar.gz#sha256=77edd6811471282740846672a996348e963b5fa4220780f126c71481ad21d5a5\n",
            "Best match: visdom 0.1.8.8\n",
            "Processing visdom-0.1.8.8.tar.gz\n",
            "Writing /tmp/easy_install-nbawsirb/visdom-0.1.8.8/setup.cfg\n",
            "Running visdom-0.1.8.8/setup.py -q bdist_egg --dist-dir /tmp/easy_install-nbawsirb/visdom-0.1.8.8/egg-dist-tmp-pkddbvhe\n",
            "warning: manifest_maker: MANIFEST.in, line 5: 'recursive-include' expects <dir> <pattern1> <pattern2> ...\n",
            "\n",
            "warning: no previously-included files matching '__pycache__' found under directory '*'\n",
            "warning: no previously-included files matching '*.py[co]' found under directory '*'\n",
            "creating /usr/local/lib/python3.6/dist-packages/visdom-0.1.8.8-py3.6.egg\n",
            "Extracting visdom-0.1.8.8-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding visdom 0.1.8.8 to easy-install.pth file\n",
            "Installing visdom script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/visdom-0.1.8.8-py3.6.egg\n",
            "Searching for websocket-client\n",
            "Reading https://pypi.org/simple/websocket-client/\n",
            "Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl#sha256=1151d5fb3a62dc129164292e1227655e4bbc5dd5340a5165dfae61128ec50aa9\n",
            "Best match: websocket-client 0.56.0\n",
            "Processing websocket_client-0.56.0-py2.py3-none-any.whl\n",
            "Installing websocket_client-0.56.0-py2.py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "writing requirements to /usr/local/lib/python3.6/dist-packages/websocket_client-0.56.0-py3.6.egg/EGG-INFO/requires.txt\n",
            "Adding websocket-client 0.56.0 to easy-install.pth file\n",
            "Installing wsdump.py script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/websocket_client-0.56.0-py3.6.egg\n",
            "Searching for torchfile\n",
            "Reading https://pypi.org/simple/torchfile/\n",
            "Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz#sha256=a53dfe134b737845a9f2cb24fe0585317874f965932cebdb0439d13c8da4136e\n",
            "Best match: torchfile 0.1.0\n",
            "Processing torchfile-0.1.0.tar.gz\n",
            "Writing /tmp/easy_install-q7lj7_8o/torchfile-0.1.0/setup.cfg\n",
            "Running torchfile-0.1.0/setup.py -q bdist_egg --dist-dir /tmp/easy_install-q7lj7_8o/torchfile-0.1.0/egg-dist-tmp-gqa8y1om\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "Moving torchfile-0.1.0-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding torchfile 0.1.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/torchfile-0.1.0-py3.6.egg\n",
            "Searching for nltk==3.2.5\n",
            "Best match: nltk 3.2.5\n",
            "Adding nltk 3.2.5 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.11.0\n",
            "Best match: six 1.11.0\n",
            "Adding six 1.11.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Pillow==4.1.1\n",
            "Best match: Pillow 4.1.1\n",
            "Adding Pillow 4.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pyzmq==17.0.0\n",
            "Best match: pyzmq 17.0.0\n",
            "Adding pyzmq 17.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tornado==4.5.3\n",
            "Best match: tornado 4.5.3\n",
            "Adding tornado 4.5.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for requests==2.18.4\n",
            "Best match: requests 2.18.4\n",
            "Adding requests 2.18.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scipy==1.1.0\n",
            "Best match: scipy 1.1.0\n",
            "Adding scipy 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.14.6\n",
            "Best match: numpy 1.14.6\n",
            "Adding numpy 1.14.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for olefile==0.46\n",
            "Best match: olefile 0.46\n",
            "Adding olefile 0.46 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for urllib3==1.22\n",
            "Best match: urllib3 1.22\n",
            "Adding urllib3 1.22 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for idna==2.6\n",
            "Best match: idna 2.6\n",
            "Adding idna 2.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for certifi==2019.3.9\n",
            "Best match: certifi 2019.3.9\n",
            "Adding certifi 2019.3.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for AQM==1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N8_OLWc-Uigz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!sudo chmod 777 /usr/local/lib/python3.6/dist-packages"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ue0F7PqQkUdF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train.py\n"
      ]
    },
    {
      "metadata": {
        "id": "tci22X4o7Dd7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cGJDlkZqP0tg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HgS2qpEpCUcl",
        "colab_type": "code",
        "outputId": "f63de7be-e131-43c3-b597-d165da640594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install markdown2\n",
        "!pip install options\n",
        "!pip install dataloader"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: markdown2 in /usr/local/lib/python3.6/dist-packages/markdown2-2.3.7-py3.6.egg (2.3.7)\n",
            "Collecting options\n",
            "  Downloading https://files.pythonhosted.org/packages/93/4b/9b6336e41dc5b971aa7db120e625ca4f3c43400e3073aac67cf25f61079a/options-1.4.10-py3-none-any.whl\n",
            "Collecting combomethod~=1.0.12 (from options)\n",
            "  Downloading https://files.pythonhosted.org/packages/6e/19/a33293ad8405eb506849ed468f632e01e2f861f5470ed6a1a5eff7526693/combomethod-1.0.12-py2.py3-none-any.whl\n",
            "Collecting six~=1.12.0 (from options)\n",
            "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
            "Collecting nulltype~=2.3.1 (from options)\n",
            "  Downloading https://files.pythonhosted.org/packages/00/0f/47dde1a3cceac9858da0bfb92d2279bf5f993ed075b72983e92efc297db3/nulltype-2.3.1-py2.py3-none-any.whl\n",
            "Collecting chainmap~=1.0.3 (from options)\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/f7/78ddc379d5dc2bbdcf690c3663396d8be5f2c7bc76d30012beef620272ee/chainmap-1.0.3-py3-none-any.whl\n",
            "\u001b[31mspacy 2.0.18 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mjupyter-console 6.0.0 has requirement prompt-toolkit<2.1.0,>=2.0.0, but you'll have prompt-toolkit 1.0.15 which is incompatible.\u001b[0m\n",
            "\u001b[31mimgaug 0.2.8 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mgoogle-colab 1.0.0 has requirement six~=1.11.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mfastai 1.0.51 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mdatascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: combomethod, six, nulltype, chainmap, options\n",
            "  Found existing installation: six 1.11.0\n",
            "    Uninstalling six-1.11.0:\n",
            "      Successfully uninstalled six-1.11.0\n",
            "Successfully installed chainmap-1.0.3 combomethod-1.0.12 nulltype-2.3.1 options-1.4.10 six-1.12.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting dataloader\n",
            "  Downloading https://files.pythonhosted.org/packages/b4/73/1f6af2e50749071b763e0b963fd23de2b00e3846ebf3296e025081a59d00/dataloader-2.0.tar.gz\n",
            "Building wheels for collected packages: dataloader\n",
            "  Building wheel for dataloader (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3a/a0/74/7190a79f983c5276ddcfe888612746a633d8ed0c0eaf7fa42d\n",
            "Successfully built dataloader\n",
            "Installing collected packages: dataloader\n",
            "Successfully installed dataloader-2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0DSXXoHGkTr5",
        "colab_type": "code",
        "outputId": "7153bb8e-f173-423a-d62e-d26e40e97526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import random\n",
        "import pprint\n",
        "from six.moves import range\n",
        "from markdown2 import markdown\n",
        "from time import gmtime, strftime\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import options\n",
        "from dataloader import VisDialDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from eval_utils.rank_answerer import rankABot\n",
        "from eval_utils.rank_questioner import rankQBot\n",
        "from utils import utilities as utils\n",
        "from utils.visualize import VisdomVisualize\n",
        "\n",
        "try:\n",
        "    import nsml\n",
        "    from nsml import IS_ON_NSML\n",
        "    print('able to use nsml')\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "#---------------------------------------------------------------------------------------\n",
        "# Setup\n",
        "#---------------------------------------------------------------------------------------\n",
        "\n",
        "# Read the command line options\n",
        "params = options.readCommandLine()\n",
        "\n",
        "# Seed rng for reproducibility\n",
        "random.seed(params['randomSeed'])\n",
        "torch.manual_seed(params['randomSeed'])\n",
        "if params['useGPU']:\n",
        "    torch.cuda.manual_seed_all(params['randomSeed'])\n",
        "\n",
        "# Setup dataloader\n",
        "splits = ['train', 'val', 'test']\n",
        "\n",
        "dataset = VisDialDataset(params, splits)\n",
        "\n",
        "# Params to transfer from dataset\n",
        "transfer = ['vocabSize', 'numOptions', 'numRounds']\n",
        "for key in transfer:\n",
        "    if hasattr(dataset, key):\n",
        "        params[key] = getattr(dataset, key)\n",
        "\n",
        "# Create save path and checkpoints folder\n",
        "os.makedirs('checkpoints', exist_ok=True)\n",
        "os.mkdir(params['savePath'])\n",
        "\n",
        "# Loading Modules\n",
        "parameters = []\n",
        "aBot = None\n",
        "qBot = None\n",
        "aqmBot = None\n",
        "\n",
        "# Loading A-Bot\n",
        "if params['trainMode'] in ['sl-abot', 'rl-full-QAf', 'aqmbot-dep']:\n",
        "    aBot, loadedParams, optim_state = utils.loadModel(params, 'abot')\n",
        "    for key in loadedParams:\n",
        "        params[key] = loadedParams[key]\n",
        "    if params['trainMode'] not in ['aqmbot-dep']:\n",
        "        parameters.extend(aBot.parameters())\n",
        "    # aBot = nn.DataParallel(aBot)\n",
        "\n",
        "\n",
        "\n",
        "# Loading Q-Bot\n",
        "if params['trainMode'] in ['sl-qbot', 'rl-full-QAf']:\n",
        "    qBot, loadedParams, optim_state = utils.loadModel(params, 'qbot')\n",
        "    for key in loadedParams:\n",
        "        params[key] = loadedParams[key]\n",
        "\n",
        "    # Filtering parameters which require a gradient update\n",
        "    parameters.extend(filter(lambda p: p.requires_grad, qBot.parameters()))\n",
        "    # parameters.extend(qBot.parameters())\n",
        "    # qBot = nn.DataParallel(qBot)\n",
        "\n",
        "# Loading AQM-Bot\n",
        "if params['trainMode'] in ['aqmbot-ind', 'aqmbot-dep']:\n",
        "    aqmBot, loadedParams, optim_state = utils.loadModel(params, 'AQM-qbot')\n",
        "    for key in loadedParams:\n",
        "        params[key] = loadedParams[key]\n",
        "\n",
        "    # Filtering parameters which require a gradient update\n",
        "    parameters.extend(filter(lambda p: p.requires_grad, aqmBot.parameters()))\n",
        "    # parameters.extend(qBot.parameters())\n",
        "    # aqmBot = nn.DataParallel(aqmBot)\n",
        "\n",
        "# Setup pytorch dataloader\n",
        "dataset.split = 'train'\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=params['batchSize'],\n",
        "    shuffle=False,\n",
        "    num_workers=params['numWorkers'],\n",
        "    drop_last=True,\n",
        "    collate_fn=dataset.collate_fn,\n",
        "    pin_memory=False)\n",
        "\n",
        "# Initializing visdom environment for plotting data\n",
        "viz = VisdomVisualize(\n",
        "    enable=bool(params['enableVisdom']),\n",
        "    env_name=params['visdomEnv'],\n",
        "    server=params['visdomServer'],\n",
        "    port=params['visdomServerPort'])\n",
        "pprint.pprint(params)\n",
        "viz.addText(pprint.pformat(params, indent=4))\n",
        "\n",
        "# Setup optimizer\n",
        "if params['continue']:\n",
        "    # Continuing from a loaded checkpoint restores the following\n",
        "    startIterID = params['ckpt_iterid'] + 1  # Iteration ID\n",
        "    lRate = params['ckpt_lRate']  # Learning rate\n",
        "    print(\"Continuing training from iterId[%d]\" % startIterID)\n",
        "else:\n",
        "    # Beginning training normally, without any checkpoint\n",
        "    lRate = params['learningRate']\n",
        "    startIterID = 0\n",
        "\n",
        "optimizer = optim.Adam(parameters, lr=lRate)\n",
        "if params['continue']:  # Restoring optimizer state\n",
        "    print(\"Restoring optimizer state dict from checkpoint\")\n",
        "    optimizer.load_state_dict(optim_state)\n",
        "runningLoss = None\n",
        "\n",
        "mse_criterion = nn.MSELoss(size_average=True, reduce=True)\n",
        "\n",
        "numIterPerEpoch = dataset.numDataPoints['train'] // params['batchSize']\n",
        "print('\\n%d iter per epoch.' % numIterPerEpoch)\n",
        "\n",
        "if params['useCurriculum']:\n",
        "    if params['continue']:\n",
        "        rlRound = max(0, 9 - (startIterID // numIterPerEpoch))\n",
        "    else:\n",
        "        rlRound = params['numRounds'] - 1\n",
        "else:\n",
        "    rlRound = 0\n",
        "\n",
        "#---------------------------------------------------------------------------------------\n",
        "# Training\n",
        "#---------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def batch_iter(dataloader):\n",
        "    for epochId in range(params['numEpochs']):\n",
        "        for idx, batch in enumerate(dataloader):\n",
        "            if params['trainSplit'] is not None:\n",
        "                if (params['trainSplit'] == 'last' and idx < numIterPerEpoch // 2) or \\\n",
        "                    (params['trainSplit'] == 'first' and idx >= numIterPerEpoch // 2):\n",
        "                    continue\n",
        "            yield epochId, idx, batch\n",
        "\n",
        "\n",
        "start_t = timer()\n",
        "for epochId, idx, batch in batch_iter(dataloader):\n",
        "    # Keeping track of iterId and epoch\n",
        "    iterId = startIterID + idx + (epochId * numIterPerEpoch)\n",
        "    epoch = iterId // numIterPerEpoch\n",
        "    gc.collect()\n",
        "\n",
        "    # Moving current batch to GPU, if available\n",
        "    if dataset.useGPU:\n",
        "        batch = {key: v.cuda() if hasattr(v, 'cuda') \\\n",
        "                                    else v for key, v in batch.items()}\n",
        "\n",
        "    image = Variable(batch['img_feat'], requires_grad=False)\n",
        "    caption = Variable(batch['cap'], requires_grad=False)\n",
        "    captionLens = Variable(batch['cap_len'], requires_grad=False)\n",
        "    gtQuestions = Variable(batch['ques'], requires_grad=False)\n",
        "    gtQuesLens = Variable(batch['ques_len'], requires_grad=False)\n",
        "    gtAnswers = Variable(batch['ans'], requires_grad=False)\n",
        "    gtAnsLens = Variable(batch['ans_len'], requires_grad=False)\n",
        "    options = Variable(batch['opt'], requires_grad=False)\n",
        "    optionLens = Variable(batch['opt_len'], requires_grad=False)\n",
        "    gtAnsId = Variable(batch['ans_id'], requires_grad=False)\n",
        "\n",
        "    # Initializing optimizer and losses\n",
        "    optimizer.zero_grad()\n",
        "    loss = 0\n",
        "    qBotLoss = 0\n",
        "    aBotLoss = 0\n",
        "    aqmBotLoss = 0\n",
        "    rlLoss = 0\n",
        "    featLoss = 0\n",
        "    qBotRLLoss = 0\n",
        "    aBotRLLoss = 0\n",
        "    predFeatures = None\n",
        "    initialGuess = None\n",
        "    numRounds = params['numRounds']\n",
        "    # numRounds = 1 # Override for debugging lesser rounds of dialog\n",
        "\n",
        "    # Setting training modes for both bots and observing captions, images where needed\n",
        "    if aBot: \n",
        "        if params['trainMode'] in ['aqmbot-ind']:\n",
        "            aBot.eval(), aBot.reset()\n",
        "        else:\n",
        "            aBot.train(), aBot.reset()\n",
        "        aBot.observe(-1, image=image, caption=caption, captionLens=captionLens)\n",
        "    if qBot:\n",
        "        qBot.train(), qBot.reset()\n",
        "        qBot.observe(-1, caption=caption, captionLens=captionLens)\n",
        "    if aqmBot:\n",
        "        aqmBot.train(), aqmBot.reset()\n",
        "        aqmBot.observe(-1, caption=caption, captionLens=captionLens, image=image)\n",
        "\n",
        "    # Q-Bot image feature regression ('guessing') only occurs if Q-Bot is present\n",
        "    if params['trainMode'] in ['sl-qbot', 'rl-full-QAf']:\n",
        "        initialGuess = qBot.predictImage()\n",
        "        prevFeatDist = mse_criterion(initialGuess, image)\n",
        "        featLoss += prevFeatDist\n",
        "\n",
        "    if params['trainMode'] in ['aqmbot-ind']:\n",
        "        initialGuess = aqmBot.predictImage()\n",
        "        prevFeatDist = mse_criterion(initialGuess, image)\n",
        "        featLoss += prevFeatDist\n",
        "\n",
        "    # Iterating over dialog rounds\n",
        "    for round in range(numRounds):\n",
        "        '''\n",
        "        Loop over rounds of dialog. Currently three modes of training are\n",
        "        supported:\n",
        "\n",
        "            sl-abot :\n",
        "                Supervised pre-training of A-Bot model using cross\n",
        "                entropy loss with ground truth answers\n",
        "\n",
        "            sl-qbot :\n",
        "                Supervised pre-training of Q-Bot model using cross\n",
        "                entropy loss with ground truth questions for the\n",
        "                dialog model and mean squared error loss for image\n",
        "                feature regression (i.e. image prediction)\n",
        "\n",
        "            rl-full-QAf :\n",
        "                RL-finetuning of A-Bot and Q-Bot in a cooperative\n",
        "                setting where the common reward is the difference\n",
        "                in mean squared error between the current and\n",
        "                previous round of Q-Bot's image prediction.\n",
        "\n",
        "                Annealing: In order to ease in the RL objective,\n",
        "                fine-tuning starts with first N-1 rounds of SL\n",
        "                objective and last round of RL objective - the\n",
        "                number of RL rounds are increased by 1 after\n",
        "                every epoch until only RL objective is used for\n",
        "                all rounds of dialog.\n",
        "            \n",
        "            aqmbot-ind :\n",
        "                Training AQM bot with ind setting. \n",
        "\n",
        "        '''\n",
        "        # Tracking components which require a forward pass\n",
        "        # A-Bot dialog model\n",
        "        forwardABot = (params['trainMode'] == 'sl-abot'\n",
        "                       or (params['trainMode'] == 'rl-full-QAf'\n",
        "                           and round < rlRound))\n",
        "        # Q-Bot dialog model\n",
        "        forwardQBot = (params['trainMode'] == 'sl-qbot'\n",
        "                       or (params['trainMode'] == 'rl-full-QAf'\n",
        "                           and round < rlRound))\n",
        "\n",
        "        forwardAQMBot = params['trainMode'] in ['aqmbot-ind', 'aqmbot-dep']\n",
        "        # Q-Bot feature regression network\n",
        "        forwardFeatNet = (forwardQBot or params['trainMode'] == 'rl-full-QAf'\n",
        "                            or forwardAQMBot)\n",
        "\n",
        "        # Answerer Forward Pass\n",
        "        if forwardABot:\n",
        "            # Observe Ground Truth (GT) question\n",
        "            aBot.observe(\n",
        "                round,\n",
        "                ques=gtQuestions[:, round],\n",
        "                quesLens=gtQuesLens[:, round])\n",
        "            # Observe GT answer for teacher forcing\n",
        "            aBot.observe(\n",
        "                round,\n",
        "                ans=gtAnswers[:, round],\n",
        "                ansLens=gtAnsLens[:, round])\n",
        "            ansLogProbs = aBot.forward()\n",
        "            # Cross Entropy (CE) Loss for Ground Truth Answers\n",
        "            aBotLoss += utils.maskedNll(ansLogProbs,\n",
        "                                        gtAnswers[:, round].contiguous())\n",
        "\n",
        "        # Questioner Forward Pass (dialog model)\n",
        "        if forwardQBot:\n",
        "            # Observe GT question for teacher forcing\n",
        "            qBot.observe(\n",
        "                round,\n",
        "                ques=gtQuestions[:, round],\n",
        "                quesLens=gtQuesLens[:, round])\n",
        "            quesLogProbs = qBot.forward()\n",
        "            # Cross Entropy (CE) Loss for Ground Truth Questions\n",
        "            qBotLoss += utils.maskedNll(quesLogProbs,\n",
        "                                        gtQuestions[:, round].contiguous())\n",
        "            # Observe GT answer for updating dialog history\n",
        "            qBot.observe(\n",
        "                round,\n",
        "                ans=gtAnswers[:, round],\n",
        "                ansLens=gtAnsLens[:, round])\n",
        "        \n",
        "        #### Never train qBot now\n",
        "        if forwardAQMBot:\n",
        "            # Observe GT question for teacher forcing\n",
        "            aqmBot.observe(\n",
        "                round,\n",
        "                ques=gtQuestions[:, round],\n",
        "                quesLens=gtQuesLens[:, round])\n",
        "            if params['trainMode'] in ['aqmbot-dep']:\n",
        "                aBot.observe(round, ques=gtQuestions[:, round], quesLens=gtQuesLens[:, round])\n",
        "            quesLogProbs = aqmBot.forward()\n",
        "            # Cross Entropy (CE) Loss for Ground Truth Questions\n",
        "            '''\n",
        "            aqmBotLoss += utils.maskedNll(quesLogProbs,\n",
        "                                        gtQuestions[:, round].contiguous())\n",
        "            '''\n",
        "            # Observe GT answer for updating dialog history\n",
        "            if params['trainMode'] in ['aqmbot-ind']:\n",
        "                gtAns = gtAnswers[:, round]\n",
        "                gtLens = gtAnsLens[:, round]\n",
        "            else:\n",
        "                gtAns, gtLens = aBot.forwardDecode(inference='greedy', beamSize=1)\n",
        "                aBot.observe(round, ans=gtAns, ansLens=gtLens)\n",
        "            aqmBot.observe(\n",
        "                round,\n",
        "                ans=gtAns,\n",
        "                ansLens=gtLens)\n",
        "            appAnsLogProbs = aqmBot.aForward() \n",
        "            aqmBotLoss  += utils.maskedNll(appAnsLogProbs,\n",
        "                                        gtAns.contiguous())\n",
        "            \n",
        "\n",
        "        # In order to stay true to the original implementation, the feature\n",
        "        # regression network makes predictions before dialog begins and for\n",
        "        # the first 9 rounds of dialog. This can be set to 10 if needed.\n",
        "        MAX_FEAT_ROUNDS = 9\n",
        "\n",
        "        # Questioner feature regression network forward pass\n",
        "        if forwardFeatNet and round < MAX_FEAT_ROUNDS and not forwardAQMBot:\n",
        "            # Make an image prediction after each round\n",
        "            predFeatures = qBot.predictImage()\n",
        "            featDist = mse_criterion(predFeatures, image)\n",
        "            featLoss += featDist\n",
        "        \n",
        "        #### Never train qBot now\n",
        "        if forwardAQMBot and forwardFeatNet:\n",
        "            '''\n",
        "            predFeatures = aqmBot.predictImage()\n",
        "            featDist = mse_criterion(predFeatures, image)\n",
        "            featLoss += featDist\n",
        "            '''\n",
        "\n",
        "        # A-Bot and Q-Bot interacting in RL rounds\n",
        "        if params['trainMode'] == 'rl-full-QAf' and round >= rlRound:\n",
        "            # Run one round of conversation\n",
        "            questions, quesLens = qBot.forwardDecode(inference='sample')\n",
        "            qBot.observe(round, ques=questions, quesLens=quesLens)\n",
        "            aBot.observe(round, ques=questions, quesLens=quesLens)\n",
        "            answers, ansLens = aBot.forwardDecode(inference='sample')\n",
        "            aBot.observe(round, ans=answers, ansLens=ansLens)\n",
        "            qBot.observe(round, ans=answers, ansLens=ansLens)\n",
        "\n",
        "            # Q-Bot makes a guess at the end of each round\n",
        "            predFeatures = qBot.predictImage()\n",
        "\n",
        "            # Computing reward based on Q-Bot's predicted image\n",
        "            featDist = mse_criterion(predFeatures, image)\n",
        "\n",
        "            reward = prevFeatDist.detach() - featDist\n",
        "            prevFeatDist = featDist\n",
        "\n",
        "            qBotRLLoss = qBot.reinforce(reward)\n",
        "            if params['rlAbotReward']:\n",
        "                aBotRLLoss = aBot.reinforce(reward)\n",
        "            rlLoss += torch.mean(aBotRLLoss)\n",
        "            rlLoss += torch.mean(qBotRLLoss)\n",
        "\n",
        "    # Loss coefficients\n",
        "    rlCoeff = 1\n",
        "    rlLoss = rlLoss * rlCoeff\n",
        "    featLoss = featLoss * params['featLossCoeff']\n",
        "    # Averaging over rounds\n",
        "    qBotLoss = (params['CELossCoeff'] * qBotLoss) / numRounds\n",
        "    aBotLoss = (params['CELossCoeff'] * aBotLoss) / numRounds\n",
        "    aqmBotLoss = (params['CELossCoeff'] * aqmBotLoss) / numRounds\n",
        "    featLoss = featLoss / numRounds  #/ (numRounds+1)\n",
        "    rlLoss = rlLoss / numRounds\n",
        "    # Total loss\n",
        "    loss = qBotLoss + aBotLoss + rlLoss + featLoss + aqmBotLoss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Tracking a running average of loss\n",
        "    if runningLoss is None:\n",
        "        runningLoss = loss.data[0]\n",
        "    else:\n",
        "        runningLoss = 0.95 * runningLoss + 0.05 * loss.data[0]\n",
        "\n",
        "    # Decay learning rate\n",
        "    if lRate > params['minLRate']:\n",
        "        for gId, group in enumerate(optimizer.param_groups):\n",
        "            optimizer.param_groups[gId]['lr'] *= params['lrDecayRate']\n",
        "        lRate *= params['lrDecayRate']\n",
        "        if iterId % 10 == 0:  # Plot learning rate till saturation\n",
        "            viz.linePlot(iterId, lRate, 'learning rate', 'learning rate')\n",
        "\n",
        "    # RL Annealing: Every epoch after the first, decrease rlRound\n",
        "    if iterId % numIterPerEpoch == 0 and iterId > 0:\n",
        "        if params['trainMode'] == 'rl-full-QAf':\n",
        "            rlRound = max(0, rlRound - 1)\n",
        "            print('Using rl starting at round {}'.format(rlRound))\n",
        "\n",
        "    # Print every now and then\n",
        "    if iterId % 10 == 0:\n",
        "        end_t = timer()  # Keeping track of iteration(s) time\n",
        "        curEpoch = float(iterId) / numIterPerEpoch\n",
        "        timeStamp = strftime('%a %d %b %y %X', gmtime())\n",
        "        printFormat = '[%s][Ep: %.2f][Iter: %d][Time: %5.2fs][Loss: %.3g]'\n",
        "        printFormat += '[lr: %.3g]'\n",
        "        printInfo = [\n",
        "            timeStamp, curEpoch, iterId, end_t - start_t, loss.data[0], lRate\n",
        "        ]\n",
        "        start_t = end_t\n",
        "        print(printFormat % tuple(printInfo))\n",
        "\n",
        "        # Update line plots\n",
        "        if isinstance(aBotLoss, Variable):\n",
        "            viz.linePlot(iterId, aBotLoss.data[0], 'aBotLoss', 'train CE')\n",
        "        if isinstance(qBotLoss, Variable):\n",
        "            viz.linePlot(iterId, qBotLoss.data[0], 'qBotLoss', 'train CE')\n",
        "        if isinstance(rlLoss, Variable):\n",
        "            viz.linePlot(iterId, rlLoss.data[0], 'rlLoss', 'train')\n",
        "        if isinstance(featLoss, Variable):\n",
        "            viz.linePlot(iterId, featLoss.data[0], 'featLoss',\n",
        "                         'train FeatureRegressionLoss')\n",
        "        viz.linePlot(iterId, loss.data[0], 'loss', 'train loss')\n",
        "        viz.linePlot(iterId, runningLoss, 'loss', 'running train loss')\n",
        "\n",
        "    # Evaluate every epoch\n",
        "    if iterId % (numIterPerEpoch // 1) == 0 or (params['trainSplit'] == 'last' and \\\n",
        "        (iterId - numIterPerEpoch // 2) % (numIterPerEpoch // 1) == 0):\n",
        "        # Keeping track of epochID\n",
        "        curEpoch = float(iterId) / numIterPerEpoch\n",
        "        epochId = (1.0 * iterId / numIterPerEpoch) + 1\n",
        "\n",
        "        # Set eval mode\n",
        "        if aBot and aBot.training:\n",
        "            aBot.eval()\n",
        "        if qBot:\n",
        "            qBot.eval()\n",
        "\n",
        "        if params['enableVisdom']:\n",
        "            # Printing visdom environment name in terminal\n",
        "            print(\"Currently on visdom env [%s]\" % (params['visdomEnv']))\n",
        "\n",
        "        # Mapping iteration count to epoch count\n",
        "        viz.linePlot(iterId, epochId, 'iter x epoch', 'epochs')\n",
        "\n",
        "        print('Performing validation...')\n",
        "        if aBot and params['trainMode'] in ['sl-abot', 'rl-full-QAf'] and 'ques' in batch:\n",
        "            print(\"aBot Validation:\")\n",
        "\n",
        "            # NOTE: A-Bot validation is slow, so adjust exampleLimit as needed\n",
        "            rankMetrics = rankABot(\n",
        "                aBot,\n",
        "                dataset,\n",
        "                'val',\n",
        "                scoringFunction=utils.maskedNll,\n",
        "                exampleLimit=25 * params['batchSize'])\n",
        "\n",
        "            for metric, value in rankMetrics.items():\n",
        "                viz.linePlot(\n",
        "                    epochId, value, 'val - aBot', metric, xlabel='Epochs')\n",
        "\n",
        "            if 'logProbsMean' in rankMetrics:\n",
        "                logProbsMean = params['CELossCoeff'] * rankMetrics[\n",
        "                    'logProbsMean']\n",
        "                viz.linePlot(iterId, logProbsMean, 'aBotLoss', 'val CE')\n",
        "\n",
        "                if params['trainMode'] == 'sl-abot':\n",
        "                    valLoss = logProbsMean\n",
        "                    viz.linePlot(iterId, valLoss, 'loss', 'val loss')\n",
        "\n",
        "        if qBot:\n",
        "            print(\"qBot Validation:\")\n",
        "            rankMetrics, roundMetrics = rankQBot(qBot, dataset, 'val')\n",
        "\n",
        "            for metric, value in rankMetrics.items():\n",
        "                viz.linePlot(\n",
        "                    epochId, value, 'val - qBot', metric, xlabel='Epochs')\n",
        "\n",
        "            viz.linePlot(iterId, epochId, 'iter x epoch', 'epochs')\n",
        "\n",
        "            if 'logProbsMean' in rankMetrics:\n",
        "                logProbsMean = params['CELossCoeff'] * rankMetrics[\n",
        "                    'logProbsMean']\n",
        "                viz.linePlot(iterId, logProbsMean, 'qBotLoss', 'val CE')\n",
        "\n",
        "            if 'featLossMean' in rankMetrics:\n",
        "                featLossMean = params['featLossCoeff'] * (\n",
        "                    rankMetrics['featLossMean'])\n",
        "                viz.linePlot(iterId, featLossMean, 'featLoss',\n",
        "                             'val FeatureRegressionLoss')\n",
        "\n",
        "            if 'logProbsMean' in rankMetrics and 'featLossMean' in rankMetrics:\n",
        "                if params['trainMode'] == 'sl-qbot':\n",
        "                    valLoss = logProbsMean + featLossMean\n",
        "                    viz.linePlot(iterId, valLoss, 'loss', 'val loss')\n",
        "\n",
        "    # Save the model after every epoch\n",
        "    if iterId % numIterPerEpoch == 0 or (params['trainSplit'] == 'last' and idx == numIterPerEpoch // 2):\n",
        "        params['ckpt_iterid'] = iterId\n",
        "        params['ckpt_lRate'] = lRate\n",
        "\n",
        "        if aBot and params['trainMode'] in ['sl-abot', 'rl-full-QAf']:\n",
        "            saveFile = os.path.join(params['savePath'],\n",
        "                                    'abot_ep_%d.vd' % curEpoch)\n",
        "            print('Saving model: ' + saveFile)\n",
        "            utils.saveModel(aBot, optimizer, saveFile, params)\n",
        "        if qBot:\n",
        "            saveFile = os.path.join(params['savePath'],\n",
        "                                    'qbot_ep_%d_q.vd' % curEpoch)\n",
        "            utils.saveModel(qBot, optimizer, saveFile, params)\n",
        "        if aqmBot:\n",
        "            saveFile = os.path.join(params['savePath'],\n",
        "                                    'aqmbot_ep_%d_q.vd' % curEpoch)\n",
        "            utils.saveModel(aqmBot, optimizer, saveFile, params)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-708a90b7d049>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmarkdown2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmarkdown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgmtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrftime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtimeit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefault_timer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'markdown2'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "uT_pbvO6j_4b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Evaluate.py"
      ]
    },
    {
      "metadata": {
        "id": "rm3SCH0txf6z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import random\n",
        "import pprint\n",
        "from six.moves import range\n",
        "from markdown2 import markdown\n",
        "from time import gmtime, strftime\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import options\n",
        "from dataloader import VisDialDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from eval_utils.dialog_generate import dialogDump\n",
        "from eval_utils.rank_answerer import rankABot\n",
        "from eval_utils.rank_questioner import rankQBot, rankQABots\n",
        "from utils import utilities as utils\n",
        "from utils.visualize import VisdomVisualize\n",
        "import visdom\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from eval_utils.aqm_runner import AQMRunner\n",
        "\n",
        "try:\n",
        "    from nsml import Visdom\n",
        "    print('able to use nsml Visdom')\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "def getAQMSetting(params):\n",
        "    if params[\"aqmstartFrom\"]:\n",
        "        strategy = \"depA\"\n",
        "        qBot = os.path.splitext(os.path.basename(params[\"qstartFrom\"]))[0]\n",
        "        aBot = os.path.splitext(os.path.basename(params[\"startFrom\"]))[0]\n",
        "        aprxABot = os.path.splitext(os.path.basename(params[\"aqmstartFrom\"]))[0]\n",
        "    else:\n",
        "        aBot = os.path.splitext(os.path.basename(params[\"startFrom\"]))[0]\n",
        "        aprxABot = os.path.splitext(os.path.basename(params[\"aqmAStartFrom\"]))[0]\n",
        "        strategy = \"trueA\" if aBot == aprxABot else \"indA\"\n",
        "        qBot = os.path.splitext(os.path.basename(params[\"aqmQStartFrom\"]))[0]\n",
        "\n",
        "    if \"delta\" in qBot:\n",
        "        assert \"delta\" in aBot and \"delta\" in aprxABot\n",
        "    else:\n",
        "        assert \"delta\" not in aBot and \"delta\" not in aprxABot\n",
        "\n",
        "    if \"delta\" in qBot:\n",
        "        hpSetting = \"delta\"\n",
        "    else:\n",
        "        hpSetting = \"nondelta\"\n",
        "\n",
        "    aqmSetting = {\n",
        "        \"hpSetting\": hpSetting,\n",
        "        \"strategy\": strategy,\n",
        "        \"qBot\": qBot,\n",
        "        \"aBot\": aBot,\n",
        "        \"aprxABot\": aprxABot,\n",
        "    }\n",
        "    return aqmSetting\n",
        "\n",
        "def main(params):\n",
        "    aqmSetting = None\n",
        "    if (\"AQMBotRank\" in params[\"evalModeList\"]\n",
        "            or \"AQMdialog\" in params[\"evalModeList\"]\n",
        "            or \"AQMdemo\" in params[\"evalModeList\"]):\n",
        "        aqmSetting = getAQMSetting(params)\n",
        "\n",
        "    # setup dataloader\n",
        "    dlparams = params.copy()\n",
        "    dlparams['useIm'] = True\n",
        "    dlparams['useHistory'] = True\n",
        "    dlparams['numRounds'] = 10\n",
        "    splits = ['val', 'test']\n",
        "\n",
        "    dataset = VisDialDataset(dlparams, splits)\n",
        "\n",
        "    # Transferring dataset parameters\n",
        "    transfer = ['vocabSize', 'numOptions', 'numRounds']\n",
        "    for key in transfer:\n",
        "        if hasattr(dataset, key):\n",
        "            params[key] = getattr(dataset, key)\n",
        "\n",
        "    if 'numRounds' not in params:\n",
        "        params['numRounds'] = 10\n",
        "\n",
        "    # Always load checkpoint parameters with continue flag\n",
        "    params['continue'] = True\n",
        "\n",
        "    excludeParams = ['batchSize', 'visdomEnv', 'startFrom', 'qstartFrom', 'trainMode', \\\n",
        "        'evalModeList', 'inputImg', 'inputQues', 'inputJson', 'evalTitle', 'beamSize', \\\n",
        "        'enableVisdom', 'visdomServer', 'visdomServerPort', 'randomCaption', 'zeroCaption',\n",
        "                     'numImg', 'numQ', 'numA', 'alpha',\n",
        "                     'qbeamSize', 'gamma', 'delta', 'lambda',\n",
        "                     'onlyGuesser', 'randQ', 'gen1Q', 'gtQ', 'randA', 'noHistory',\n",
        "                     'slGuesser', 'resampleEveryDialog']\n",
        "\n",
        "    aBot = None\n",
        "    qBot = None\n",
        "    aqmBot = None\n",
        "\n",
        "    # load aBot\n",
        "    print('load aBot')\n",
        "    if params['startFrom']:\n",
        "        aBot, loadedParams, _ = utils.loadModel(params, 'abot', overwrite=True)\n",
        "        assert aBot.encoder.vocabSize == dataset.vocabSize, \"Vocab size mismatch!\"\n",
        "        for key in loadedParams:\n",
        "            params[key] = loadedParams[key]\n",
        "        aBot.eval()\n",
        "\n",
        "    # Retaining certain dataloder parameters\n",
        "    for key in excludeParams:\n",
        "        params[key] = dlparams[key]\n",
        "\n",
        "    print('load qBot')\n",
        "    # load qBot\n",
        "    if params['qstartFrom'] and not params['aqmstartFrom']:\n",
        "        qBot, loadedParams, _ = utils.loadModel(params, 'qbot', overwrite=True)\n",
        "        assert qBot.encoder.vocabSize == params[\n",
        "            'vocabSize'], \"Vocab size mismatch!\"\n",
        "        for key in loadedParams:\n",
        "            params[key] = loadedParams[key]\n",
        "        qBot.eval()\n",
        "\n",
        "    # Retaining certain dataloder parameters\n",
        "    for key in excludeParams:\n",
        "        params[key] = dlparams[key]\n",
        "\n",
        "    print('load AQM-Bot')\n",
        "    # load aqmBot\n",
        "    if params['aqmstartFrom']:  # abot of AQM\n",
        "        assert params['qstartFrom']  # qbot of AQM\n",
        "\n",
        "        aqmBot, loadedParams, _ = utils.loadModel(params, 'AQM-qbot', overwrite=True)\n",
        "        assert aqmBot.questioner.encoder.vocabSize == params[\n",
        "            'vocabSize'], \"Vocab size mismatch!\"\n",
        "        for key in loadedParams:\n",
        "            params[key] = loadedParams[key]\n",
        "        aqmBot.eval()\n",
        "\n",
        "        # load qBot\n",
        "        for key in excludeParams:\n",
        "            params[key] = dlparams[key]\n",
        "        aqmQ, loadedParams, _ = utils.loadModel(params, 'qbot', overwrite=True)\n",
        "        assert aqmQ.encoder.vocabSize == params[\n",
        "            'vocabSize'], \"Vocab size mismatch!\"\n",
        "        for key in loadedParams:\n",
        "            params[key] = loadedParams[key]\n",
        "        aqmQ.eval()\n",
        "        for key in excludeParams:\n",
        "            params[key] = dlparams[key]\n",
        "        aqmBot.setQuestioner(aqmQ)\n",
        "\n",
        "    elif params['aqmQStartFrom']:\n",
        "        from visdial.models.aqm_questioner import AQMQuestioner\n",
        "        aqmBot = AQMQuestioner()\n",
        "        aqmBot.eval()\n",
        "\n",
        "        params['qstartFrom'] = params['aqmQStartFrom']\n",
        "        aqmQ, loadedParams, _ = utils.loadModel(params, 'qbot', overwrite=True)\n",
        "        assert aqmQ.encoder.vocabSize == params[\n",
        "            'vocabSize'], \"Vocab size mismatch!\"\n",
        "        for key in loadedParams:\n",
        "            params[key] = loadedParams[key]\n",
        "        aqmQ.eval()\n",
        "        for key in excludeParams:\n",
        "            params[key] = dlparams[key]\n",
        "        aqmBot.setQuestioner(aqmQ)\n",
        "\n",
        "        params['startFrom'] = params['aqmAStartFrom']\n",
        "        aqmA, loadedParams, _ = utils.loadModel(params, 'abot', overwrite=True)\n",
        "        assert aqmA.encoder.vocabSize == dataset.vocabSize, \"Vocab size mismatch!\"\n",
        "        for key in loadedParams:\n",
        "            params[key] = loadedParams[key]\n",
        "        aqmA.eval()\n",
        "        aqmBot.setAppAnswerer(aqmA)\n",
        "\n",
        "    for key in excludeParams:\n",
        "        params[key] = dlparams[key]\n",
        "\n",
        "    pprint.pprint(params)\n",
        "    #viz.addText(pprint.pformat(params, indent=4))\n",
        "    print(\"Running evaluation!\")\n",
        "\n",
        "    numRounds = params['numRounds']\n",
        "    if 'ckpt_iterid' in params:\n",
        "        iterId = params['ckpt_iterid'] + 1\n",
        "    else:\n",
        "        iterId = -1\n",
        "\n",
        "    if 'test' in splits:\n",
        "        split = 'test'\n",
        "        splitName = 'test - {}'.format(params['evalTitle'])\n",
        "    else:\n",
        "        split = 'val'\n",
        "        splitName = 'full Val - {}'.format(params['evalTitle'])\n",
        "\n",
        "    print(\"Using split %s\" % split)\n",
        "    dataset.split = split\n",
        "\n",
        "    if 'ABotRank' in params['evalModeList']:\n",
        "        if params['aqmstartFrom']:\n",
        "            aBot = aqmBot.appAnswerer\n",
        "            print('evaluating appBot of AQM')\n",
        "        print(\"Performing ABotRank evaluation\")\n",
        "        rankMetrics = rankABot(\n",
        "            aBot, dataset, split, scoringFunction=utils.maskedNll,\n",
        "            expLowerLimit=params['expLowerLimit'],\n",
        "            expUpperLimit=params['expUpperLimit'])\n",
        "        print(rankMetrics)\n",
        "        for metric, value in rankMetrics.items():\n",
        "            plotName = splitName + ' - ABot Rank'\n",
        "            #viz.linePlot(iterId, value, plotName, metric, xlabel='Iterations')\n",
        "\n",
        "    if 'QBotRank' in params['evalModeList']:\n",
        "        print(\"Performing QBotRank evaluation\")\n",
        "        rankMetrics, roundRanks = rankQBot(qBot, dataset, split,\n",
        "            expLowerLimit=params['expLowerLimit'],\n",
        "            expUpperLimit=params['expUpperLimit'],\n",
        "            verbose=1)\n",
        "        for metric, value in rankMetrics.items():\n",
        "            plotName = splitName + ' - QBot Rank'\n",
        "            #viz.linePlot(iterId, value, plotName, metric, xlabel='Iterations')\n",
        "\n",
        "        for r in range(numRounds + 1):\n",
        "            for metric, value in roundRanks[r].items():\n",
        "                plotName = '[Iter %d] %s - QABots Rank Roundwise' % \\\n",
        "                            (iterId, splitName)\n",
        "                #viz.linePlot(r, value, plotName, metric, xlabel='Round')\n",
        "\n",
        "    if 'QABotsRank' in params['evalModeList']:\n",
        "        print(\"Performing QABotsRank evaluation\")\n",
        "        outputPredFile = \"data/visdial/visdial/output_predictions_rollout.h5\"\n",
        "        rankMetrics, roundRanks = rankQABots(\n",
        "            qBot, aBot, dataset, split, beamSize=params['beamSize'],\n",
        "            expLowerLimit=params['expLowerLimit'],\n",
        "            expUpperLimit=params['expUpperLimit'],\n",
        "            zeroCaption=params['zeroCaption'],\n",
        "            randomCaption=params['randomCaption'],\n",
        "            numRounds=params['runRounds'])\n",
        "        for metric, value in rankMetrics.items():\n",
        "            plotName = splitName + ' - QABots Rank'\n",
        "            #viz.linePlot(iterId, value, plotName, metric, xlabel='Iterations')\n",
        "\n",
        "        for r in range(numRounds + 1):\n",
        "            for metric, value in roundRanks[r].items():\n",
        "                plotName = '[Iter %d] %s - QBot All Metrics vs Round'%\\\n",
        "                            (iterId, splitName)\n",
        "                #viz.linePlot(r, value, plotName, metric, xlabel='Round')\n",
        "\n",
        "    if 'AQMBotRank' in params['evalModeList']:\n",
        "        print(\"Performing AQMBotRank evaluation\")\n",
        "        outputPredFile = \"data/visdial/visdial/output_predictions_rollout.h5\"\n",
        "        rankMetrics, roundRanks = AQMRunner(\n",
        "            aqmBot, aBot, dataset, split, beamSize=params['beamSize'], realQA=params['aqmRealQA'],\n",
        "            saveLogs=params['saveLogs'], showQA=params['showQA'],\n",
        "            expLowerLimit=params['expLowerLimit'],\n",
        "            expUpperLimit=params['expUpperLimit'],\n",
        "            selectedBatchIdxs=params['selectedBatchIdxs'],\n",
        "            numRounds=params['runRounds'],\n",
        "            lda=params['lambda'],\n",
        "            onlyGuesser=params['onlyGuesser'],\n",
        "            numQ=params['numQ'],\n",
        "            qbeamSize=params['qbeamSize'],\n",
        "            numImg=params['numImg'],\n",
        "            alpha=params['alpha'],\n",
        "            numA=params['numA'],\n",
        "            randQ=params['randQ'],\n",
        "            randA=params['randA'],\n",
        "            zeroCaption=params['zeroCaption'],\n",
        "            randomCaption=params['randomCaption'],\n",
        "            gamma=params['gamma'],\n",
        "            delta=params['delta'],\n",
        "            gen1Q=params['gen1Q'],\n",
        "            gtQ=params['gtQ'],\n",
        "            noHistory=params['noHistory'],\n",
        "            slGuesser=params['slGuesser'],\n",
        "            resampleEveryDialog=params['resampleEveryDialog'],\n",
        "            aqmSetting=aqmSetting,\n",
        "        ).rankQuestioner()\n",
        "        for metric, value in rankMetrics.items():\n",
        "            plotName = splitName + ' - QABots Rank'\n",
        "            #viz.linePlot(iterId, value, plotName, metric, xlabel='Iterations')\n",
        "\n",
        "        for r in range(numRounds + 1):\n",
        "            for metric, value in roundRanks[r].items():\n",
        "                plotName = '[Iter %d] %s - QBot All Metrics vs Round'%\\\n",
        "                            (iterId, splitName)\n",
        "                #viz.linePlot(r, value, plotName, metric, xlabel='Round')\n",
        "\n",
        "    if 'dialog' in params['evalModeList']:\n",
        "        print(\"Performing dialog generation...\")\n",
        "        split = 'test'\n",
        "        outputFolder = \"dialog_output/results\"\n",
        "        os.makedirs(outputFolder, exist_ok=True)\n",
        "        outputPath = os.path.join(outputFolder, \"results.json\")\n",
        "        dialogDump(\n",
        "            params,\n",
        "            dataset,\n",
        "            split,\n",
        "            aBot=aBot,\n",
        "            qBot=qBot,\n",
        "            expLowerLimit=params['expLowerLimit'],\n",
        "            expUpperLimit=params['expUpperLimit'],\n",
        "            beamSize=params['beamSize'],\n",
        "            savePath=outputPath)\n",
        "\n",
        "    if 'AQMdialog' in params['evalModeList']:\n",
        "        print(\"Performing AQM dialog generation...\")\n",
        "\n",
        "        split = 'test'\n",
        "        AQMRunner(\n",
        "            aqmBot, aBot, dataset, split, beamSize=params['beamSize'], realQA=params['aqmRealQA'],\n",
        "            saveLogs=params['saveLogs'], showQA=params['showQA'],\n",
        "            expLowerLimit=params['expLowerLimit'],\n",
        "            expUpperLimit=params['expUpperLimit'],\n",
        "            selectedBatchIdxs=params['selectedBatchIdxs'],\n",
        "            numRounds=params['runRounds'],\n",
        "            lda=params['lambda'],\n",
        "            onlyGuesser=params['onlyGuesser'],\n",
        "            numQ=params['numQ'],\n",
        "            qbeamSize=params['qbeamSize'],\n",
        "            numImg=params['numImg'],\n",
        "            alpha=params['alpha'],\n",
        "            numA=params['numA'],\n",
        "            randQ=params['randQ'],\n",
        "            randA=params['randA'],\n",
        "            zeroCaption=params['zeroCaption'],\n",
        "            randomCaption=params['randomCaption'],\n",
        "            gamma=params['gamma'],\n",
        "            delta=params['delta'],\n",
        "            gen1Q=params['gen1Q'],\n",
        "            gtQ=params['gtQ'],\n",
        "            noHistory=params['noHistory'],\n",
        "            slGuesser=params['slGuesser'],\n",
        "            resampleEveryDialog=params['resampleEveryDialog'],\n",
        "            aqmSetting=aqmSetting,\n",
        "        ).dialogDump(params)\n",
        "\n",
        "\n",
        "    #viz.addText(\"Evaluation run complete!\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # read the command line options\n",
        "    params = options.readCommandLine()\n",
        "\n",
        "    # seed rng for reproducibility\n",
        "    manualSeed = 1234\n",
        "    # manualSeed = params['randomSeed']\n",
        "    if \"AQMdemo\" not in params[\"evalModeList\"]:\n",
        "        random.seed(manualSeed)\n",
        "        np.random.seed(manualSeed)\n",
        "        torch.manual_seed(manualSeed)\n",
        "        if params['useGPU']:\n",
        "            torch.cuda.manual_seed_all(manualSeed)\n",
        "    main(params)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}